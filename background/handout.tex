\documentclass{article}
\usepackage{natbib}
\usepackage[colorlinks=true,urlcolor=black]{hyperref}

\author{Tatiana Boura and Stasinos Konstantopoulos}

\title{Kolmogorov-Arnold Networks \\
  Theoretical Background, current approaches, and potential next steps}

\date{28 Nov 2024}

\begin{document}

\maketitle

\begin{abstract}

In this talk we will present the Kolmogorov-Arnold Network (KAN),
a new and promising approach for machine learning. KAN shifts the
objective of training from parameterizing how fixed activation
functions contribute to the next layer, to parameterizing activation
functions that are then fed to the next layer under simple summation.

We will first discuss the mathematical background on
multivariate functions and in particular the Kolmogorov-Arnold Representation
Theorem that underlies KANs. We will also discuss works that use the
Representation Theorem and subsequent mathematical results as a tool for
understanding deep learning and how it differs from the perceptron. We will
then focus on recent ML articles and present the original KAN article as well
as relevant literature on its extensions and applications. We will close with
presenting and discussing our plans in this field, exploring opportunities to
collaborate.

\end{abstract}

\nocite{*}
\bibliographystyle{plainnat}
\bibliography{biblio}

\end{document}
